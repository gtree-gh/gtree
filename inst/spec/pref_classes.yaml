# preference classes
payoff:
	descr: 'Risk-neutral payoff maximizer.'
	defaultName: payoff
	params:
	fun: payoffUtil

ineqAv:
	descr: >
	  Inequality aversion as in Fehr and Schmidt (1999).<br>
	  If \(x_i\) is the monetary payoff of player i, her utility
	  is computed as follows:
	  \[u_i = x_i
	    - \frac \alpha {n-1} \sum_{j \ne i}\max(x_j-x_i,0)
	    - \frac \beta {n-1} \sum_{j \ne i}\max(x_i-x_j,0)
	   \]
	  where \(n\) is the number of players,
	  \(\alpha\) is the envy parameter and \(\beta\) the guilt parameter.
	  <br>Note that round values for alpha and beta,
	  like <code>alpha=1</code> and <code>beta=0.5</code> can yield
	  a large number of multiple equilibria in certain games,
	  while the multiplicity vanishes for close-by parameter values like
	  <code>alpha=0.99</code> or <code>alpha=1.01</code>.
	defaultName: 'ineq_99_49'
	params:
		alpha:
			descr: 'the degree of envy'
			default: 0.99
		beta:
			descr: 'the degree of guilt'
			default: 0.49
	fun: ineqAvUtil

lossAv:
	descr: >
	  Loss aversion with a single reference point \(r_i\) for each player<br>
	  If \(x_i\) is the monetary payoff of player i, her utility is given by
	  the following simple linear specification of loss aversion:

	  \[u_i = \max(x_i-r_i,0) - \lambda \max(r_i-x_i,0)\]

	  <br>The parameter \(\lambda\) measures the degree of loss aversion.
	  It is typically assumed that \(\lambda > 1\), i.e. losses loom
	  larger than gains. A common choice is \(\lambda = 2\).
	  <br>The reference point can be a formula and thereby depend
	  on the game. The example below choses the reference point for
	  each player i, as the mean of her lowest and
	  highest possible payoffs in the game.
	  <br>
	  Note that unlike the classic macroeconomic notion that people are risk-averse over
	  their expected life-time income, loss aversion means that subjects narrowly
	  consider only the risk of losses and gains in the current experiment.
	  See Mathew Rabin's article
	  "Risk Aversion and Expected-Utility Theory: A Calibration Theorem." (Econometrica, 2000)
	  for an exposition why behavior towards risk in small stake economic experiments,
	  is only consistent with such narrow bracketing.
	defaultName: 'lossAvCenter'
	params:
		r:
			descr: 'Reference point, can be a formula'
			default: '(min(payoff_i)+max(payoff_i))/2'
		lambda:
			descr: degree of loss aversion
			default: 2
	fun: lossAvUtil

unifLossAv:
	descr: >
	  This is an alternative formulation of loss aversion,
		with a continuum of reference points
		that are uniformely distributed between rmin and rmax.<br>
		Between rmin and rmax, the resulting utility function then has
		a quadratic form, while beyond rmin or rmax it is linear.
	defaultName: 'unifLossAv_min_max'
	params:
		rmin:
			descr: the lowest reference point
			default: 'min(payoff_i)'
		rmax:
			descr: the highest reference point
			default: 'max(payoff_i)'
		lambda:
			descr: degree of loss aversion
			default: 2
	fun: unifLossAvUtil

WSumMin:
	descr: >
	  This preferences assume that all
		players maximize total welfare W
		defined as the sum of all payoffs plus
		<code>min_weight</code> times the minimal payoff.
		<br><br>For <code>min_weight=0</code>, everybody plays as if to
		maximize the expected sum of utility (utilitarian welfare).
	defaultName: 'WSumMin_1'
	params:
		min_weight:
			descr: 'The weight on the minimal payoff.'
			default: 1
	fun: WSumMin
